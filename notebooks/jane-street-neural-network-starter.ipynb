{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jane Street: Neural Network Starter\n\nI try implementing a simple Tensorflow Keras neural network here. Train in Version 17.\n\n**Caution:** The GroupCV method applied in this notebook may cause time leakage problem. Please use [Purged Time-Series CV][1] instead.\n\n[1]: https://www.kaggle.com/marketneutral/purged-time-series-cv-xgboost-optuna"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc\n# import cudf\nimport pandas as pd\nimport numpy as np\n# import cupy as cp\nimport janestreet\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\n\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# print('Loading...')\n# train = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\ntrain = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv', nrows = 3)\nfeatures = [c for c in train.columns if 'feature' in c]\n\n# print('Filling...')\n# f_mean = train[features[1:]].mean()\n# train = train.query('weight > 0').reset_index(drop = True)\n# train[features[1:]] = train[features[1:]].fillna(f_mean)\n# train['action'] = (train['resp'] > 0).astype('int')\n\n# print('Converting...')\n# train = train.to_pandas()\n# f_mean = f_mean.values.get()\n# np.save('f_mean.npy', f_mean)\n\n# print('Finish.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)): \n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4096\nhidden_units = [384, 896, 896, 394]\ndropout_rates = [0.10143786981358652, 0.19720339053599725, 0.2703017847244654, 0.23148340929571917, 0.2357768967777311]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\n# oof = np.zeros(len(train['action']))\n# gkf = GroupKFold(n_splits = 5)\n# for fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n    \n#     X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values\n#     y_tr, y_val = train.loc[tr, 'action'].values, train.loc[te, 'action'].values\n    \n#     ckp_path = f'JSModel_{fold}.hdf5'\n#     model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n#     rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = 0, \n#                             min_delta = 1e-4, mode = 'max')\n#     ckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n#                           save_best_only = True, save_weights_only = True, mode = 'max')\n#     es = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n#                        baseline = None, restore_best_weights = True, verbose = 0)\n#     model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs = 1000, \n#               batch_size = batch_size, callbacks = [rlr, ckp, es], verbose = 0)\n                \n#     oof[te] += model.predict(X_val, batch_size = batch_size * 4).ravel()\n#     score = roc_auc_score(y_val, oof[te])\n#     print(f'Fold {fold} ROC AUC:\\t', score)\n    \n#     # Finetune 3 epochs on validation set with small learning rate\n#     model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate / 100)\n#     model.load_weights(ckp_path)\n#     model.fit(X_val, y_val, epochs = 3, batch_size = batch_size, verbose = 0)\n#     model.save_weights(ckp_path)\n    \n#     K.clear_session()\n#     del model\n#     rubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# score_oof = roc_auc_score(train['action'].values, oof)\n# print(score_oof)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_models = 2\n\nmodels = []\nfor i in range(num_models):\n    clf = create_mlp(len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n    clf.load_weights(f'../input/js-nn-models/JSModel_{i}.hdf5')\n#     clf.load_weights(f'./JSModel_{i}.hdf5')\n    models.append(clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean = np.load('../input/js-nn-models/f_mean.npy')\n# f_mean = np.load('./f_mean.npy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submitting\n\nJust use two models to reduce running time."},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\nenv_iter = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"opt_th = 0.5\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        pred = 0.\n        for clf in models:\n            pred += clf(x_tt, training = False).numpy().item() / num_models\n#         pred = models[0](x_tt, training = False).numpy().item()\n        pred_df.action = np.where(pred >= opt_th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}